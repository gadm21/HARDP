{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('hardp')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n hardp ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import utils\n",
    "import data_utils \n",
    "import model_utils \n",
    "\n",
    "# reload the module\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(model_utils)\n",
    "\n",
    "\n",
    "from utils import * \n",
    "from data_utils import *\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  7\n",
      "file:../HARB4/person 1/study01.txt has 51495 samples\n",
      "file:../HARB4/person 1/study01.txt has 51495 samples\n",
      "file:../HARB4/person 1/study00.txt has 85926 samples\n",
      "file:../HARB4/person 1/study00.txt has 85926 samples\n",
      "file:../HARB4/person 1/sleep00.txt has 520005 samples\n",
      "file:../HARB4/person 1/sleep00.txt has 100000 samples\n",
      "file:../HARB4/person 1/walk01.txt has 51150 samples\n",
      "file:../HARB4/person 1/walk01.txt has 51150 samples\n",
      "file:../HARB4/person 1/walk00.txt has 64185 samples\n",
      "file:../HARB4/person 1/walk00.txt has 64185 samples\n",
      "file:../HARB4/person 1/idle01.txt has 74466 samples\n",
      "file:../HARB4/person 1/idle01.txt has 74466 samples\n",
      "file:../HARB4/person 1/idle00.txt has 51120 samples\n",
      "file:../HARB4/person 1/idle00.txt has 51120 samples\n"
     ]
    }
   ],
   "source": [
    "limit_len = 100_000\n",
    "data, labels = read_data(data_dir, original_labels = original_labels, original_features = original_features, seq_len = seq_len, offset = offset, limit_len = limit_len) \n",
    "\n",
    "train_data, pub_data, test_data = split_data_KD(data, labels) \n",
    "cat_labels = to_categorical(train_data[1], num_classes = len(original_labels))\n",
    "cat_test_labels = to_categorical(test_data[1], num_classes = len(original_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_HARDataset = HARDataset(train_data[0], cat_labels)\n",
    "test_HARDataset = HARDataset(test_data[0], cat_test_labels)\n",
    "train_dataloader = DataLoader(train_HARDataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_HARDataset, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = HARNet(n_lstm_layers = 2, n_features = 4, n_hidden = 30, n_classes = 4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:28<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.294636Train Loss: 1.382035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:36<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.517887Train Loss: 1.348567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:27<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.569405Train Loss: 1.280947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:28<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.753676Train Loss: 1.219846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:28<00:00,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.755420Train Loss: 1.168679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5) : \n",
    "    \n",
    "    train(model, criterion, optimizer, train_dataloader, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:32<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.943627Train Loss: 1.120806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:30<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.967525Train Loss: 1.075161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:27<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.971201Train Loss: 1.032490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:26<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.973888Train Loss: 0.988918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:25<00:00,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.974736Train Loss: 0.946258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5) : \n",
    "    \n",
    "    train(model, criterion, optimizer, train_dataloader, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.985539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, test_dataloader, privacy_engine=None, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP Training\n",
    "\n",
    "## Notes on DP\n",
    "\n",
    "In addition to all the considerations you normally take into account when choosing batch size, training models with DP adds another one - privacy cost.\n",
    "\n",
    "Because of the threat model we assume and the way we add noise to the gradients, larger batch sizes (to a certain extent) generally help convergence. We add the same amount of noise to each gradient update (scaled to the norm of one sample in the batch) regardless of the batch size. What this means is that as the batch size increases, the relative amount of noise added decreases. while preserving the same epsilon guarantee.\n",
    "\n",
    "You should, however, keep in mind that increasing batch size has its price in terms of epsilon, which grows at O(sqrt(batch_size)) as we train (therefore larger batches make it grow faster). The good strategy here is to experiment with multiple combinations of batch_size and noise_multiplier to find the one that provides the best possible quality at acceptable privacy guarantee.\n",
    "\n",
    "There's another side to this - memory. Opacus computes and stores per sample gradients, so for every normal gradient, Opacus will store n=batch_size per-sample gradients on each step, thus increasing the memory footprint by at least O(batch_size). In reality, however, the peak memory requirement is O(batch_size^2) compared to a non-private model. This is because some intermediate steps in per sample gradient computation involve operations on two matrices, each with batch_size as one of the dimensions.\n",
    "\n",
    "The good news is, we can pick the most appropriate batch size, regardless of memory constraints. Opacus has built-in support for virtual batches. Using it we can separate physical steps (gradient computation) and logical steps (noise addition and parameter updates): use larger batches for training, while keeping memory footprint low. Below we will specify two constants:\n",
    "\n",
    "MAX_PHYSICAL_BATCH_SIZE defines the maximum batch size we can afford from a memory standpoint, and only affects computation speed\n",
    "BATCH_SIZE, on the other hand, will affect only convergence and privacy guarantee.\n",
    "\n",
    "___________________________________________________________________________________\n",
    "noise_multiplier. It defines the trade-off between privacy and accuracy. Adding more noise will provide stronger privacy guarantees, but will also hurt model quality. In this run, the PrivacyEngine will determine this value based on the target values of EPSILON, DELTA, and EPOCHS. For the default settings, this will set noise_multiplier to about 0.4.\n",
    "___________________________________________________________________________________\n",
    "max_grad_norm. Defines the maximum magnitude of L2 norms to which we clip per sample gradients. There is a bit of tug of war with this threshold: on the one hand, a low threshold means that we will clip many gradients, hurting convergence, so we might be tempted to raise it. However, recall that we add noise with std=noise_multiplier * max_grad_norm so we will pay for the increased threshold with more noise. In most cases you can rely on the model being quite resilient to clipping (after the first few iterations your model will tend to adjust so that its gradients stay below the clipping threshold), so you can often just keep the default value (=1.0) and focus on tuning batch_size and noise_multiplier instead. That being said, sometimes clipping hurts the model so it may be worth experimenting with different clipping thresholds, like we are doing in this tutorial.\n",
    "___________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "errors = ModuleValidator.validate(model, strict=False)\n",
    "errors[-5:]\n",
    "\n",
    "# model = ModuleValidator.fix(model)\n",
    "# ModuleValidator.validate(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/functorch/_C.cpython-39-darwin.so, 0x0002): Symbol not found: (__ZN2at4_ops10as_strided4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEES8_NS5_8optionalIS7_EE)\n  Referenced from: '/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/functorch/_C.cpython-39-darwin.so'\n  Expected in: '/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad@lakeheadu.ca/My Drive/dead repos/HARDP/Knowledge_distillation/KD.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mRMSprop(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLR)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model, optimizer, train_loader \u001b[39m=\u001b[39m privacy_engine\u001b[39m.\u001b[39;49mmake_private_with_epsilon(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     module\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     data_loader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     target_epsilon\u001b[39m=\u001b[39;49mEPSILON,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     target_delta\u001b[39m=\u001b[39;49mDELTA,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     max_grad_norm\u001b[39m=\u001b[39;49mMAX_GRAD_NORM,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gadmohamed/Library/CloudStorage/GoogleDrive-ggad%40lakeheadu.ca/My%20Drive/dead%20repos/HARDP/Knowledge_distillation/KD.ipynb#X34sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing sigma=\u001b[39m\u001b[39m{\u001b[39;00moptimizer\u001b[39m.\u001b[39mnoise_multiplier\u001b[39m}\u001b[39;00m\u001b[39m and C=\u001b[39m\u001b[39m{\u001b[39;00mMAX_GRAD_NORM\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/privacy_engine.py:513\u001b[0m, in \u001b[0;36mPrivacyEngine.make_private_with_epsilon\u001b[0;34m(self, module, optimizer, data_loader, target_epsilon, target_delta, epochs, max_grad_norm, batch_first, loss_reduction, poisson_sampling, clipping, noise_generator, grad_sample_mode, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccountant) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    507\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    508\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre calling make_private_with_epsilon with non-zero privacy budget \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malready spent. Returned noise_multiplier assumes zero starting point, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mso your overall privacy budget will be higher.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m     )\n\u001b[0;32m--> 513\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_private(\n\u001b[1;32m    514\u001b[0m     module\u001b[39m=\u001b[39;49mmodule,\n\u001b[1;32m    515\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    516\u001b[0m     data_loader\u001b[39m=\u001b[39;49mdata_loader,\n\u001b[1;32m    517\u001b[0m     noise_multiplier\u001b[39m=\u001b[39;49mget_noise_multiplier(\n\u001b[1;32m    518\u001b[0m         target_epsilon\u001b[39m=\u001b[39;49mtarget_epsilon,\n\u001b[1;32m    519\u001b[0m         target_delta\u001b[39m=\u001b[39;49mtarget_delta,\n\u001b[1;32m    520\u001b[0m         sample_rate\u001b[39m=\u001b[39;49msample_rate,\n\u001b[1;32m    521\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    522\u001b[0m         accountant\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccountant\u001b[39m.\u001b[39;49mmechanism(),\n\u001b[1;32m    523\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    524\u001b[0m     ),\n\u001b[1;32m    525\u001b[0m     max_grad_norm\u001b[39m=\u001b[39;49mmax_grad_norm,\n\u001b[1;32m    526\u001b[0m     batch_first\u001b[39m=\u001b[39;49mbatch_first,\n\u001b[1;32m    527\u001b[0m     loss_reduction\u001b[39m=\u001b[39;49mloss_reduction,\n\u001b[1;32m    528\u001b[0m     noise_generator\u001b[39m=\u001b[39;49mnoise_generator,\n\u001b[1;32m    529\u001b[0m     grad_sample_mode\u001b[39m=\u001b[39;49mgrad_sample_mode,\n\u001b[1;32m    530\u001b[0m     poisson_sampling\u001b[39m=\u001b[39;49mpoisson_sampling,\n\u001b[1;32m    531\u001b[0m     clipping\u001b[39m=\u001b[39;49mclipping,\n\u001b[1;32m    532\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/privacy_engine.py:399\u001b[0m, in \u001b[0;36mPrivacyEngine.make_private\u001b[0;34m(self, module, optimizer, data_loader, noise_multiplier, max_grad_norm, batch_first, loss_reduction, poisson_sampling, clipping, noise_generator, grad_sample_mode)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    394\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mModule parameters are different than optimizer Parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         )\n\u001b[1;32m    397\u001b[0m distributed \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(module, (DPDDP, DDP))\n\u001b[0;32m--> 399\u001b[0m module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_model(\n\u001b[1;32m    400\u001b[0m     module,\n\u001b[1;32m    401\u001b[0m     batch_first\u001b[39m=\u001b[39;49mbatch_first,\n\u001b[1;32m    402\u001b[0m     loss_reduction\u001b[39m=\u001b[39;49mloss_reduction,\n\u001b[1;32m    403\u001b[0m     grad_sample_mode\u001b[39m=\u001b[39;49mgrad_sample_mode,\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m poisson_sampling:\n\u001b[1;32m    406\u001b[0m     module\u001b[39m.\u001b[39mregister_backward_hook(forbid_accumulation_hook)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/privacy_engine.py:242\u001b[0m, in \u001b[0;36mPrivacyEngine._prepare_model\u001b[0;34m(self, module, batch_first, loss_reduction, grad_sample_mode)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[39mreturn\u001b[39;00m module\n\u001b[1;32m    241\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[39mreturn\u001b[39;00m wrap_model(\n\u001b[1;32m    243\u001b[0m         module,\n\u001b[1;32m    244\u001b[0m         grad_sample_mode\u001b[39m=\u001b[39;49mgrad_sample_mode,\n\u001b[1;32m    245\u001b[0m         batch_first\u001b[39m=\u001b[39;49mbatch_first,\n\u001b[1;32m    246\u001b[0m         loss_reduction\u001b[39m=\u001b[39;49mloss_reduction,\n\u001b[1;32m    247\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/grad_sample/utils.py:58\u001b[0m, in \u001b[0;36mwrap_model\u001b[0;34m(model, grad_sample_mode, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m grad_sample_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfunctorch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     57\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mforce_functorch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/grad_sample/grad_sample_module.py:141\u001b[0m, in \u001b[0;36mGradSampleModule.__init__\u001b[0;34m(self, m, batch_first, loss_reduction, strict, force_functorch)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_reduction \u001b[39m=\u001b[39m loss_reduction\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforce_functorch \u001b[39m=\u001b[39m force_functorch\n\u001b[0;32m--> 141\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_hooks(\n\u001b[1;32m    142\u001b[0m     loss_reduction\u001b[39m=\u001b[39;49mloss_reduction,\n\u001b[1;32m    143\u001b[0m     batch_first\u001b[39m=\u001b[39;49mbatch_first,\n\u001b[1;32m    144\u001b[0m     force_functorch\u001b[39m=\u001b[39;49mforce_functorch,\n\u001b[1;32m    145\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/grad_sample/grad_sample_module.py:202\u001b[0m, in \u001b[0;36mGradSampleModule.add_hooks\u001b[0;34m(self, loss_reduction, batch_first, force_functorch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m force_functorch \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mtype\u001b[39m(module) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGRAD_SAMPLERS:\n\u001b[0;32m--> 202\u001b[0m     prepare_layer(module, batch_first\u001b[39m=\u001b[39;49mbatch_first)\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautograd_grad_sample_hooks\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    205\u001b[0m     module\u001b[39m.\u001b[39mregister_forward_hook(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture_activations_hook)\n\u001b[1;32m    206\u001b[0m )\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautograd_grad_sample_hooks\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    209\u001b[0m     module\u001b[39m.\u001b[39mregister_backward_hook(\n\u001b[1;32m    210\u001b[0m         partial(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     )\n\u001b[1;32m    216\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/opacus/grad_sample/functorch.py:15\u001b[0m, in \u001b[0;36mprepare_layer\u001b[0;34m(layer, batch_first)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_layer\u001b[39m(layer, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m    Prepare a layer to compute grad samples using functorch.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m    The grad samples are computed by redoing the forward and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m        batch_first: whether the input is batch_first or not\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mfunctorch\u001b[39;00m \u001b[39mimport\u001b[39;00m grad, make_functional, vmap\n\u001b[1;32m     17\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(layer\u001b[39m.\u001b[39mbuffers())) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     18\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     19\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis layer has buffers and is not supported by Opacus\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/fl/lib/python3.9/site-packages/functorch/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _C\n\u001b[1;32m      9\u001b[0m \u001b[39m# Top-level APIs. Please think carefully before adding something to the\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# top-level namespace:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# - private helper functions should go into functorch._src\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# functorch transforms\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvmap\u001b[39;00m \u001b[39mimport\u001b[39;00m vmap\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/functorch/_C.cpython-39-darwin.so, 0x0002): Symbol not found: (__ZN2at4_ops10as_strided4callERKNS_6TensorEN3c108ArrayRefINS5_6SymIntEEES8_NS5_8optionalIS7_EE)\n  Referenced from: '/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/functorch/_C.cpython-39-darwin.so'\n  Expected in: '/Users/gadmohamed/miniforge3/envs/fl/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'"
     ]
    }
   ],
   "source": [
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 20\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "model = HARNet(n_lstm_layers = 2, n_features = 4, n_hidden = 30, n_classes = 4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_dataloader,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")\n",
    "\n",
    "print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('hardp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
